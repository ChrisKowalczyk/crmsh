.TRY Cluster scripts
.INP: script
.INP: list
.EXT crm_resource --show-metadata ocf:heartbeat:apache
.EXT crm_resource --show-metadata ocf:heartbeat:IPaddr2
.EXT crm_resource --show-metadata ocf:heartbeat:Filesystem
.EXT crm_resource --show-metadata ocf:heartbeat:mysql
.EXT crm_resource --show-metadata ocf:heartbeat:db2
.EXT crm_resource --show-metadata ocf:heartbeat:exportfs
.EXT crm_resource --show-metadata systemd:haproxy
ERROR: 2: Error when loading script haproxy: No meta-data for agent: systemd:haproxy
.EXT crm_resource --show-metadata ocf:heartbeat:LVM
.EXT crm_resource --show-metadata ocf:heartbeat:MailTo
.EXT crm_resource --show-metadata ocf:heartbeat:Raid1
Basic:

health           Verify health and configuration
mailto           E-Mail
virtual-ip       Virtual IP

Database:

database         MySQL/MariaDB Database
db2              IBM DB2 Database
db2-hadr         IBM DB2 Database with HADR
oracle           Oracle Database

Filesystem:

clvm             Cluster-aware LVM
clvm-vg          Cluster-aware LVM (Volume Group)
drbd             DRBD Block Device
filesystem       File System (mount point)
gfs2             GFS2 File System (Cloned)
lvm-drbd         LVM Group on DRBD
ocfs2            OCFS2 File System
raid-lvm         RAID Hosting LVM

NFS:

exportfs         NFS Exported File System
nfsserver        NFS Server
nfsserver-lvm-drbd NFS Server on LVM and DRBD

SAP:

sap-as           SAP ASCS Instance
sap-ci           SAP Central Instance
sap-db           SAP Database Instance
sap-simple-stack SAP Simple Stack Instance
sap-simple-stack-plus SAP SimpleStack+ Instance

Server:

apache           Apache Webserver

Stonith:

libvirt          STONITH for libvirt (kvm / Xen)
sbd              SBD, Shared storage based fencing
vmware           Fencing using vCenter / ESX Server

.INP: list all
.EXT crm_resource --show-metadata systemd:haproxy
ERROR: 3: Error when loading script haproxy: No meta-data for agent: systemd:haproxy
Basic:

health           Verify health and configuration
mailto           E-Mail
virtual-ip       Virtual IP

Database:

database         MySQL/MariaDB Database
db2              IBM DB2 Database
db2-hadr         IBM DB2 Database with HADR
oracle           Oracle Database

Filesystem:

clvm             Cluster-aware LVM
clvm-vg          Cluster-aware LVM (Volume Group)
drbd             DRBD Block Device
filesystem       File System (mount point)
gfs2             GFS2 File System (Cloned)
lvm-drbd         LVM Group on DRBD
ocfs2            OCFS2 File System
raid-lvm         RAID Hosting LVM

NFS:

exportfs         NFS Exported File System
nfsserver        NFS Server
nfsserver-lvm-drbd NFS Server on LVM and DRBD

SAP:

sap-as           SAP ASCS Instance
sap-ci           SAP Central Instance
sap-db           SAP Database Instance
sap-simple-stack SAP Simple Stack Instance
sap-simple-stack-plus SAP SimpleStack+ Instance

Script:

check-uptime     Check uptime of nodes
gfs2-base        GFS2 File System Base (Cloned)
lvm              Controls the availability of an LVM Volume Group
raid1            Manages Linux software RAID (MD) devices on shared storage
sapdb            SAP Database Instance
sapinstance      SAP Instance
sbd-device       Create SBD Device

Server:

apache           Apache Webserver

Stonith:

libvirt          STONITH for libvirt (kvm / Xen)
sbd              SBD, Shared storage based fencing
vmware           Fencing using vCenter / ESX Server

.INP: list names
apache
clvm
clvm-vg
database
db2
db2-hadr
drbd
exportfs
filesystem
gfs2
.EXT crm_resource --show-metadata systemd:haproxy
ERROR: 4: Error when loading script haproxy: No meta-data for agent: systemd:haproxy
health
libvirt
lvm-drbd
mailto
nfsserver
nfsserver-lvm-drbd
ocfs2
oracle
raid-lvm
sap-as
sap-ci
sap-db
sap-simple-stack
sap-simple-stack-plus
sbd
virtual-ip
vmware
.INP: list names all
apache
check-uptime
clvm
clvm-vg
database
db2
db2-hadr
drbd
exportfs
filesystem
gfs2
gfs2-base
haproxy
health
libvirt
lvm
lvm-drbd
mailto
nfsserver
nfsserver-lvm-drbd
ocfs2
oracle
raid-lvm
raid1
sap-as
sap-ci
sap-db
sap-simple-stack
sap-simple-stack-plus
sapdb
sapinstance
sbd
sbd-device
virtual-ip
vmware
.INP: list all names
apache
check-uptime
clvm
clvm-vg
database
db2
db2-hadr
drbd
exportfs
filesystem
gfs2
gfs2-base
haproxy
health
libvirt
lvm
lvm-drbd
mailto
nfsserver
nfsserver-lvm-drbd
ocfs2
oracle
raid-lvm
raid1
sap-as
sap-ci
sap-db
sap-simple-stack
sap-simple-stack-plus
sapdb
sapinstance
sbd
sbd-device
virtual-ip
vmware
.INP: list bogus
Traceback (most recent call last):
  File "/usr/lib/python3.4/site-packages/crmsh/ui_context.py", line 75, in run
    rv = self.execute_command() is not False
  File "/usr/lib/python3.4/site-packages/crmsh/ui_context.py", line 259, in execute_command
    rv = self.command_info.function(*arglist)
  File "/usr/lib/python3.4/site-packages/crmsh/ui_script.py", line 197, in do_list
    context.fatal_error("Unexpected argument '%s': expected  [all|names]" % (arg))
  File "/usr/lib/python3.4/site-packages/crmsh/ui_context.py", line 370, in fatal_error
    raise ValueError(msg)
ValueError: Unexpected argument 'bogus': expected  [all|names]
ERROR: 7: script.list: Unexpected argument 'bogus': expected  [all|names]
.INP: show mailto
mailto (Basic)
E-Mail

Notifies recipient by e-mail in the event of a resource takeover.

1. Notifies recipients by email in the event of resource takeover

  id (required)  (unique) 
      Identifier for the cluster resource
  email (required) 
      Email address
  subject
      Subject


.INP: verify mailto id=foo email=test@example.com subject=hello
1. Ensure mail package is installed

	mailx

2. Configure cluster resources

	primitive foo ocf:heartbeat:MailTo
		email="test@example.com"
		subject="hello"
		op start timeout="10"
		op stop timeout="10"
		op monitor interval="10" timeout="10"

	clone c-foo foo

.INP: run mailto id=foo email=test@example.com subject=hello nodes=node1 dry_run=true
INFO: 10: E-Mail
INFO: 10: Nodes: node1
** all - #!/usr/bin/env python3
import crm_script
import crm_init

crm_init.install_packages(['mailx'])
crm_script.exit_ok(True)
        
OK: 10: Ensure mail package is installed
** localhost - temporary file <<END
primitive foo ocf:heartbeat:MailTo	email="test@example.com"	subject="hello"	op start timeout="10"	op stop timeout="10"	op monitor interval="10" timeout="10"
clone c-foo foo

END

** localhost - crm --wait --no configure load update <<temporary file>>
OK: 10: Configure cluster resources
.INP: json '["show", "mailto"]'
{"name": "mailto", "shortdesc": "E-Mail", "category": "basic", "longdesc": "Notifies recipient by e-mail in the event of a resource takeover.", "steps": [{"parameters": [{"required": true, "type": "resource", "longdesc": "", "name": "id", "advanced": false, "unique": true, "shortdesc": "Identifier for the cluster resource"}, {"required": true, "type": "email", "longdesc": " The email address of sysadmin.", "example": "", "name": "email", "advanced": false, "unique": false, "shortdesc": "Email address"}, {"required": false, "type": "string", "longdesc": " The subject of the email.", "example": "", "name": "subject", "advanced": false, "unique": false, "shortdesc": "Subject"}], "shortdesc": "Notifies recipients by email in the event of resource takeover", "required": true, "longdesc": " This is a resource agent for MailTo. It sends email to a sysadmin\nwhenever  a takeover occurs."}]}
.INP: json '["verify", "mailto", {"id":"foo", "email":"test@example.com", "subject":"hello"}]'
{"name": "install", "shortdesc": "Ensure mail package is installed", "nodes": "", "longdesc": "", "text": "mailx"}
{"name": "cib", "shortdesc": "Configure cluster resources", "nodes": "", "longdesc": "", "text": "primitive foo ocf:heartbeat:MailTo\n\temail=\"test@example.com\"\n\tsubject=\"hello\"\n\top start timeout=\"10\"\n\top stop timeout=\"10\"\n\top monitor interval=\"10\" timeout=\"10\"\n\nclone c-foo foo"}
